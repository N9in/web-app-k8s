# web-app-k8s
Helm Chart для веб приложения на kubernetes\helm

## Процесс поиска и принятые решения

Решение для приложения в k8s было описано в виде Helm Chart'а, т.к. предоставляет максимальное удобство для сборки проекта и его редактирования за счёт переменных значений ключей. Таким образом внести изменения можно на ходу или отредактировав файл values.yaml. 

Решения по пунктам задания: 

1) Т.к. приложение требует 5-10 секунд для инициализации, использовался параметр spec.minReadySeconds, который задаётся через файл значений (10) и говорит о минимальном времени готовности пода. Помимо этого в readinessProbe.initialDelaySeconds тоже задано такое переменное значение (10).

2) В связи с тем, что 4 пода обеспечивают стабильную работу при пиковой нагрузке, это будет максимальным значением для автобалансировки (hpa)

3) Потребление ресурсов приложением (каждым подом) ограничивается resource.limit и resource.request в deployment. В качестве зарезервированного CPU указывается стабильное значение 0.1 CPU (100m), предельное - 0.3 как значительно большее для первых запросов (всегда можно увеличить интерактивно или через values), память везде 128M.

4) Циклы нагрузки регулируются автобалансировщиком hpa. Так при пиковой нагрузке создаются дополнительные поды (максимум - 4), ночью же при меньшей активности количество подов уменьшается до 2х. Можно уменьшить и до 1, но если под падает, нужно всё же небольшое время на поднятие нового пода, поэтому принял решение оставить 2 для лучшей стабильности и надежности.
Помимо такого решения были мысли использовать CronJob - по расписанию редактировать максимальное значение подов или фоновую программу на основном сервере,     проверяющую системную переменную времени и реализующую скрипт обновления кол-ва подов. Но решение с hpa оптимально, как мне кажется.

5) Максимальная отказоустойчивость. Здесь работают liveness и readness пробы (также можно добавить startup пробу) -- проверяют под на готовность работать с траффиком и жизнеспособность (дедлок), в случае неисправности kubelet перезапускает под. 
Также отказоустойчивость обеспечивает автоскейлинг (hpa), поддерживающий нужное количество подов в рабочем состоянии при отказах\обновлениях.
Стоит ещё сказать про мультизональный кластер, который у нас имеется по условию задания. Распределив поды по разным зонам за счёт spec.affinity и topologyKey, обеспечиваем бесперебойную работу в случае отказа одной из зон.

6) Минимальное потребление ресурсов. Опять hpa с Utilization resources, который позволит скалировать количество подов в зависимости от нагрузки, и ограничение потребления ресурсов для отдельных подов.

Также в качестве сервиса был выбран LoadBalancer, который позволит лучше распределять нагрузку по нодам (можно было использовать ingress controller с ClusterIP сервисом, но т.к. в данной задаче используется один deployment, а такая связка как я понял используется для удешевления и упрощения, это использовано не было)

### На этом всё. Благодарю за прочтение.
